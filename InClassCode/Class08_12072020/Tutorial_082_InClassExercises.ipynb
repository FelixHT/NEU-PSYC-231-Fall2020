{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In class exercises - Intro to Pandas Series and DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get and store current file path for file i/o later on in tutorial\n",
    "import os\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First import 'response_time_data.csv' data file\n",
    "* Contains RTs from 800 trials of a simple detection task from each of 20 subjects\n",
    "* Organizing into a DataFrame and then saved out in csv format\n",
    "* The index (row) and column labels are encoded in the csv file, so you'll need to read those in explcitly\n",
    "* Make sure to have a look at the DataFrame - use the df.head() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = cwd + '/response_time_data.csv'\n",
    "\n",
    "# because the row and column labels are already specified, set index_col and header = 0\n",
    "df = pd.read_csv(file_name, index_col=0, header=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now have a look at the data using built in Padas functionality\n",
    "* Check out the max/min of each row, standard deviation, percentiles, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are there missing values (NaNs) in the data?\n",
    "* one way: use the np.isnan(df) method from numpy\n",
    "* combine with np.sum to count the number of NaNs for each subject..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After you've found the NaNs for each subject, check out this function:\n",
    "[pandas.DataFrame.interpolate](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.interpolate.html#pandas.DataFrame.interpolate)\n",
    "\n",
    "* Use this function to interpolate the missing values for each subject (do not interpolate across subjects!)\n",
    "* Just use linear interpolation...\n",
    "* reassign to a new df without any NaNs (that is, after you've interpolated across any NaNs)\n",
    "* Make sure that your new df indeed doesn't have any NaNs in it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You can explore the \"Missing Values\" page for Pandas to figure out other ways of filling in missing values (or outliers)\n",
    "\n",
    "[page is here](https://pandas.pydata.org/pandas-docs/stable/missing_data.html#missing-data)\n",
    "\n",
    "* Go back to the original data set with NaNs, but this time figure out how to replace the NaNs with the mean of each subject\n",
    "* Check out the 'fillna' method..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the Pandas.DataFrame.Sample function to generate bootstrapped confidence intervals for the data from subject 11\n",
    "\n",
    "[see this page for info about the \"samples\" method](https://pandas.pydata.org/pandas-docs/version/0.22/generated/pandas.DataFrame.sample.html)\n",
    "\n",
    "\n",
    "* Take the mean interpolated data from the last step...use that for this problem\n",
    "* Resample Sub11's data with replacement 1000 times, each time pulling N samples (800 in this case)\n",
    "* On each bootstrap iteration, compute the mean of the data - this will give you a distribution of means across all resamples\n",
    "* Compute 95% confidence intervals using \"quantiles\" method or the \"percentile\" method:\n",
    "\n",
    "\n",
    "[this page for quantiles](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.quantile.html)\n",
    "[this page for percentiles](https://numpy.org/doc/stable/reference/generated/numpy.percentile.html#numpy.percentile)\n",
    "\n",
    "*Note that percentile and quantile are the same except that with percentile you use values between 0-100 and for quantile you use values between 0-1*\n",
    "    \n",
    "* Then make a plot - use the matplotlib \"errorbar\" method. Hints - because the lower and upper confidence intervals are different, pass them in as a 2 element np.array. And since you have just one data point, you can make the \"x\" parameter that you pass into errorbar just = 1. \n",
    "\n",
    "[errorbar page](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.errorbar.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
